{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import DataSets as ds\n",
    "import Layers\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb data =  100000\n",
      "nb data =  10000\n"
     ]
    }
   ],
   "source": [
    "LoadModel = False\n",
    "\n",
    "experiment_size = 100\n",
    "\n",
    "train = ds.DataSet('../Databases/data_%dk.bin'%experiment_size,'../Databases/gender_%dk.bin'%experiment_size,1000*experiment_size)\n",
    "\n",
    "test = ds.DataSet('../Databases/data_test10k.bin','../Databases/gender_test10k.bin',10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du rÃ©seau CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeuralNet(tf.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tself.unflat = Layers.unflat('unflat',48, 48, 1)\n",
    "\t\tself.cv1 = Layers.conv('conv_1', output_dim=3, filterSize=3, stride=1)\n",
    "\t\tself.mp = Layers.maxpool('pool', 2)\n",
    "\t\tself.cv2 = Layers.conv('conv_2', output_dim=6, filterSize=3, stride=1)\n",
    "\t\tself.cv3 = Layers.conv('conv_3', output_dim=12, filterSize=3, stride=1)\n",
    "\t\tself.flat = Layers.flat()\n",
    "\t\tself.fc = Layers.fc('fc', 2)\n",
    "\n",
    "\tdef __call__(self, x, log_summary):\n",
    "\t\tx = self.unflat(x, log_summary)\n",
    "\t\tx = self.cv1(x, log_summary)\n",
    "\t\tx = self.mp(x)\n",
    "\t\tx = self.cv2(x, log_summary)\n",
    "\t\tx = self.mp(x)\n",
    "\t\tx = self.cv3(x, log_summary)\n",
    "\t\tx = self.mp(x)\n",
    "\t\tx = self.flat(x)\n",
    "\t\tx = self.fc(x, log_summary)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_iter(model, optimizer, image, label, log_summary):\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\ty = model(image,log_summary)\n",
    "\t\ty = tf.nn.log_softmax(y)\n",
    "\t\tdiff = label * y\n",
    "\t\tloss = -tf.reduce_sum(diff)\n",
    "\t\tif log_summary:\n",
    "\t\t\ttf.summary.scalar('cross entropy', loss)\n",
    "\t\tgrads = tape.gradient(loss, model.trainable_variables)\n",
    "\t\toptimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "----------------------- 100k -------------------------\n",
      "-----------------------------------------------------\n",
      "def unflat unflat ? => 48 48 1\n"
     ]
    }
   ],
   "source": [
    "print (\"-----------------------------------------------------\")\n",
    "print (\"----------------------- %dk -------------------------\"%experiment_size)\n",
    "print (\"-----------------------------------------------------\")\n",
    "\n",
    "train_summary_writer = tf.summary.create_file_writer('logs %dk'%experiment_size)\n",
    "optimizer = tf.optimizers.Adam(1e-3)\n",
    "simple_cnn = ConvNeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LoadModel:\n",
    "\tckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=simple_cnn)\n",
    "\tckpt.restore('./saved_model-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build conv conv_1 3x3  1 => 3\n",
      "build conv conv_2 3x3  3 => 6\n",
      "build conv conv_3 3x3  6 => 12\n",
      "build fc fc  432 => 2\n",
      "iter=      0 accuracy - train= 46.26% - test= 47.67%\n",
      "iter=      0 - loss= 89.001869\n",
      "iter=    100 - loss= 83.145721\n",
      "iter=    200 - loss= 79.063492\n",
      "iter=    300 - loss= 65.463692\n",
      "iter=    400 - loss= 66.124283\n",
      "iter=    500 accuracy - train= 80.65% - test= 78.91%\n",
      "iter=    500 - loss= 70.258736\n",
      "iter=    600 - loss= 72.279007\n",
      "iter=    700 - loss= 44.118042\n",
      "iter=    800 - loss= 49.633751\n",
      "iter=    900 - loss= 53.008217\n",
      "iter=   1000 accuracy - train= 82.54% - test= 81.47%\n",
      "iter=   1000 - loss= 45.554482\n",
      "iter=   1100 - loss= 51.835735\n",
      "iter=   1200 - loss= 49.430199\n",
      "iter=   1300 - loss= 51.016388\n",
      "iter=   1400 - loss= 52.962700\n",
      "iter=   1500 accuracy - train= 84.20% - test= 83.34%\n",
      "iter=   1500 - loss= 61.470211\n",
      "iter=   1600 - loss= 47.179424\n",
      "iter=   1700 - loss= 41.499561\n",
      "iter=   1800 - loss= 48.957733\n",
      "iter=   1900 - loss= 58.347965\n",
      "iter=   2000 accuracy - train= 84.75% - test= 83.95%\n",
      "iter=   2000 - loss= 44.850578\n",
      "iter=   2100 - loss= 49.337803\n",
      "iter=   2200 - loss= 44.714485\n",
      "iter=   2300 - loss= 44.080044\n",
      "iter=   2400 - loss= 44.956123\n",
      "iter=   2500 accuracy - train= 85.45% - test= 84.66%\n",
      "iter=   2500 - loss= 40.265274\n",
      "iter=   2600 - loss= 36.306133\n",
      "iter=   2700 - loss= 46.913990\n",
      "iter=   2800 - loss= 43.105804\n",
      "iter=   2900 - loss= 53.813213\n",
      "iter=   3000 accuracy - train= 85.49% - test= 83.98%\n",
      "iter=   3000 - loss= 45.791275\n",
      "iter=   3100 - loss= 58.500751\n",
      "iter=   3200 - loss= 55.238571\n",
      "iter=   3300 - loss= 47.867180\n",
      "iter=   3400 - loss= 41.479172\n",
      "iter=   3500 accuracy - train= 85.18% - test= 83.95%\n",
      "iter=   3500 - loss= 52.192459\n",
      "iter=   3600 - loss= 44.595882\n",
      "iter=   3700 - loss= 41.150864\n",
      "iter=   3800 - loss= 51.086239\n",
      "iter=   3900 - loss= 36.735710\n",
      "iter=   4000 accuracy - train= 86.54% - test= 85.71%\n",
      "iter=   4000 - loss= 50.149750\n",
      "iter=   4100 - loss= 45.023888\n",
      "iter=   4200 - loss= 39.906784\n",
      "iter=   4300 - loss= 42.843204\n",
      "iter=   4400 - loss= 49.814266\n",
      "iter=   4500 accuracy - train= 86.81% - test= 86.22%\n",
      "iter=   4500 - loss= 52.607048\n",
      "iter=   4600 - loss= 35.870491\n",
      "iter=   4700 - loss= 33.861710\n",
      "iter=   4800 - loss= 52.876411\n",
      "iter=   4900 - loss= 56.025360\n"
     ]
    }
   ],
   "source": [
    "for iter in range(5000):\n",
    "\ttf.summary.experimental.set_step(iter)\n",
    "\n",
    "\tif iter % 500 == 0:\n",
    "\t\twith train_summary_writer.as_default():\n",
    "\t\t\tacc1 = train.mean_accuracy(simple_cnn) * 100\n",
    "\t\t\tacc2 = test.mean_accuracy(simple_cnn) * 100\n",
    "\t\t\tprint(\"iter= %6d accuracy - train= %.2f%% - test= %.2f%%\" % (iter, acc1, acc2))\n",
    "\n",
    "\tima, lab = train.NextTrainingBatch()\n",
    "\twith train_summary_writer.as_default():\n",
    "\t\tloss = train_one_iter(simple_cnn, optimizer, ima, lab, iter % 10 == 0)\n",
    "\tif iter % 100 == 0:\n",
    "\t\tprint(\"iter= %6d - loss= %f\" % (iter, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LoadModel:\n",
    "\tckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=simple_cnn)\n",
    "\tckpt.save('./saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=48x48 at 0x7F1DF88AAF50>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ima_init = Image.open(\"h.png\").convert('L')\n",
    "ori = ima_init.save(\"adv_Bouden_elouatiki_ori.png\")\n",
    "ima_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckpt = tf.train.Checkpoint(step = tf.Variable(1), optimizer = optimizer, net = simple_cnn)\n",
    "#ckpt.restore('./saved_model-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.862>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.mean_accuracy(simple_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ima = np.array(ima_init,dtype=np.float32).reshape([1, 2304])\n",
    "#ima = (ima - 128) / 256\n",
    "pred = tf.nn.softmax(simple_cnn(ima,False))\n",
    "pred.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mislead CNN detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2304), dtype=float32, numpy=array([[211., 230., 247., ..., 124., 130., 183.]], dtype=float32)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.constant(ima)  #Creates a constant tensor from a tensor-like object.\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 2304) dtype=float32, numpy=array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DXinit = tf.constant(0.0, shape=[1,2304])\n",
    "DX = tf.Variable(DXinit)\n",
    "DX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load a wrong label\n",
    "wrong_label = [0.0,1.0]\n",
    "wrong_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Variable DX to the input in your graph\n",
    "DXinit = tf.constant(0.0, shape=[1,2304])\n",
    "DX = tf.Variable(DXinit)\n",
    "Xmod = X + DX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train only the DX Variable\n",
    "tf.nn.log_softmax(simple_cnn(DX,False)).numpy()\n",
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Modified Image and DX Image\n",
    "modified_img = Image.fromarray(np.reshape((Xmod).numpy(),(48,48)))\n",
    "DX_img = Image.fromarray(np.reshape((DX).numpy(),(48,48)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Modified Image. Xmod\n",
    "modified_img.convert('L').save(\"adv_Bouden_elouatiki_mod.png\")\n",
    "DX_img.convert('RGB').save(\"adv_Bouden_elouatiki_DX.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As DX is very small, build an amplified image.\n",
    "A = abs(DX)*50\n",
    "A_img = Image.fromarray(np.reshape(A.numpy(),(48,48)))\n",
    "A_img.convert('L').save(\"adv_Bouden_elouatiki_Amp.png\")\n",
    "A_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Modified Image with your small script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_one_iter(model, optimizer, X,label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = model(X+DX,False)\n",
    "        y = tf.nn.log_softmax(y)\n",
    "        diff = label * y\n",
    "        loss = -tf.reduce_sum(diff)\n",
    "        grads = tape.gradient(loss,[DX]) \n",
    "        optimizer.apply_gradients(zip(grads, [DX]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=      0 - loss= 1124.360352\n",
      "iter=    100 - loss= 1111.641602\n",
      "iter=    200 - loss= 1098.963623\n",
      "iter=    300 - loss= 1086.121216\n",
      "iter=    400 - loss= 1073.338623\n",
      "iter=    500 - loss= 1060.796631\n",
      "iter=    600 - loss= 1048.674927\n",
      "iter=    700 - loss= 1036.809570\n",
      "iter=    800 - loss= 1025.098633\n",
      "iter=    900 - loss= 1013.538513\n"
     ]
    }
   ],
   "source": [
    "for iter in range(1000):\n",
    "    with train_summary_writer.as_default():\n",
    "        loss = noise_one_iter(simple_cnn, optimizer, X, wrong_label)\n",
    "    if iter % 100 == 0:\n",
    "        print(\"iter= %6d - loss= %f\" % (iter, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3505.8145>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.l2_loss([DX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(simple_cnn(X+DX,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_one_iter_regul(model, optimizer, beta, X,label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = model(X+DX2,False)\n",
    "        y = tf.nn.log_softmax(y)\n",
    "        diff = label * y\n",
    "        loss = -tf.reduce_sum(diff) + beta*tf.nn.l2_loss(DX2)\n",
    "        grads = tape.gradient(loss,[DX2]) \n",
    "        optimizer.apply_gradients(zip(grads, [DX2]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function using L2 Regularization\n",
    "DX2 = tf.Variable(DXinit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=      0 - loss= 1259.109985\n",
      "iter=    100 - loss= 1209.768921\n",
      "iter=    200 - loss= 1182.185669\n",
      "iter=    300 - loss= 1161.289307\n",
      "iter=    400 - loss= 1143.534180\n",
      "iter=    500 - loss= 1127.877686\n",
      "iter=    600 - loss= 1113.642700\n",
      "iter=    700 - loss= 1100.263428\n",
      "iter=    800 - loss= 1087.743042\n",
      "iter=    900 - loss= 1076.093872\n"
     ]
    }
   ],
   "source": [
    "for iter in range(1000):\n",
    "    with train_summary_writer.as_default():\n",
    "        loss = noise_one_iter_regul(simple_cnn, optimizer,0.01, X, wrong_label)\n",
    "    if iter % 100 == 0:\n",
    "        print(\"iter= %6d - loss= %f\" % (iter, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(simple_cnn(X,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(simple_cnn(X+DX2,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta_X2_m = Image.fromarray(np.reshape((abs(DX2)*50).numpy(),(48,48)))\n",
    "Delta_X2_m.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (tf.nn.l2_loss([DX2]) <= tf.nn.l2_loss([DX])):\n",
    "    print('penalisation L2 OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta_X2_m.convert('L').save(\"adv_Bouden_elouatiki_DX_L2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
